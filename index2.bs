<pre class="metadata">
Title: "MediaStream Image Capture"
Repository: image-capture
Group: WebAppSec
Status: ED
ED: https://w3c.github.io/mediacapture-image/
Shortname: image-capture
Level: 1
Editor: Giridhar Mandyam, w3cid 54271, Qualcomm Innovation Center Inc.
Editor: Miguel Casas-Sanchez, w3cid 82825, Google Inc., mcasas@google.com
Abstract: This document specifies methods and camera settings to produce photographic image capture. The source of images is, or can be referenced via a {{MediaStreamTrack}}.


!Participate: <a href="https://lists.w3.org/Archives/Public/public-media-capture/">Mailing list</a>
!Participate: <a href="https://github.com/w3c/mediacapture-image">GitHub repo</a> (<a href="https://github.com/w3c/mediacapture-image/issues/new">new issue</a>, <a href="https://github.com/w3c/mediacapture-image/issues">open issues</a>)

!Implementation: <a href="https://github.com/w3c/mediacapture-image/blob/gh-pages/implementation-status.md">Implementation Status</a>
!Implementation: <a href="http://caniuse.com/#feat=imagecapture">Can I use Image Capture?</a>

</pre>

# Introduction # {#introduction}

The API defined in this document captures images from a photographic device referenced through a valid {{MediaStreamTrack}}. The produced image can be in the form of a {{Blob}} (see {{takePhoto()}} method) or as a {{ImageBitmap}} (see {{grabFrame()}}). Picture-specific settings can be optionally provided as arguments that can be applied to the device for the capture.

# Image Capture API # {#imagecaptureapi"}

The User Agent must support Promises in order to implement the Image Capture API.  Any {{Promise}} object is assumed to have a resolver object, with <code>resolve()</code> and <code>reject()</code> methods associated with it.

<pre class="idl">
[Constructor(MediaStreamTrack track)]
interface ImageCapture {
   readonly attribute MediaStreamTrack videoStreamTrack;

   Promise&lt;Blob&gt;              takePhoto();
   Promise&lt;PhotoCapabilities&gt; getPhotoCapabilities();
   Promise&lt;void&gt;              setOptions(optional PhotoSettings photoSettings);
   Promise&lt;ImageBitmap&gt;       grabFrame();
};
</pre>

<div class="note">
{{takePhoto()}} returns a captured image encoded in the form of a {{Blob}}, whereas {{grabFrame()}} returns a snapshot of the {{videoStreamTrack}} video feed in the form of a non-encoded {{ImageBitmap}}.
</div>

## Attributes

<dl class="domintro">
  <dt><dfn attribute for="ImageCapture"><code>videoStreamTrack</code></dfn></dt>
  <dd>The {{MediaStreamTrack}} passed into the constructor.</dd>
</dl>

## Methods

<dl class="domintro">
  <dt><dfn constructor for="ImageCapture"><code>ImageCapture(MediaStreamTrack track)</code></dfn></dt>
  <dd>Constructs a new <a>ImageCapture</a>. The {{MediaStreamTrack}} |track| will be the value of the {{videoStreamTrack}} attribute. The {{MediaStreamTrack}} passed to the constructor MUST have its `kind` attribute set to "<code>video</code>" otherwise a {{DOMException}} of type {{NotSupportedError}} will be thrown.
  </dd>

  <dt><dfn method for="ImageCapture"><code>takePhoto()</code></dfn></dt>
  <dd>
  {{takePhoto()}} produces the result of a single photographic exposure using the video capture device sourcing the {{videoStreamTrack}}, applying any {{PhotoSettings}} previously configured, and returning an encoded image in the form of a {{Blob}} if successful. When this method is invoked:
  <ol>
    <li>If the <code>readyState</code> of {{videoStreamTrack}} provided in the constructor is not `live`, return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{InvalidStateError}}. </li>

    <li>Otherwise it MUST queue a task, using the DOM manipulation task source, that runs the following steps:
    <ol>
      <li>Gather data from {{videoStreamTrack}} into a {{Blob}} containing a single still image. The method of doing this will depend on the underlying device.
      <div class="note">
        Devices MAY temporarily stop streaming data, reconfigure themselves with the appropriate photo settings, take the photo, and then resume streaming.  In this case, the stopping and restarting of streaming SHOULD cause {{mute}} and {{unmute}} events to fire on the track in question.
      </div>
      </li>

      <li>If the UA is unable to execute the {{takePhoto()}} method for any reason (for example, upon invocation of multiple {{takePhoto()}} method calls in rapid succession), then the UA MUST return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{UnknownError}}.</li>

      <li>Return a resolved promise with the Blob object.</li>
    </ol>
    </li>
  </ol>
  </dd>

  <dt><dfn method for="ImageCapture"><code>getPhotoCapabilities()</code></dfn></dt>
  <dd>
  When {{getPhotoCapabilities()}} is used to retrieve the ranges of available configuration options and their current setting values, if any. When this method is invoked:
  <ol>
    <li>If the {{readyState}} of {{videoStreamTrack}} provided in the constructor is not {{live}}, return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{InvalidStateError}}. </li>

    <li>Otherwise it MUST queue a task, using the DOM manipulation task source, that runs the following steps:
    <ol>
      <li>Gather data from {{videoStreamTrack}} into a {{PhotoCapabilities}} object containing the available capabilities of the device, including ranges where appropriate. The resolved {{PhotoCapabilities}} will also include the current conditions in which the capabilities of the device are found. The method of doing this will depend on the underlying device. </li>

      <li>If the UA is unable to execute the {{getPhotoCapabilities()}} method for any reason (for example, the {{MediaStreamTrack}} being ended asynchronously), then the UA MUST return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{OperationError}}.</li>

      <li>Return a resolved promise with the {{PhotoCapabilities}} object.</li>
    </ol>
    </li>
  </ol>
  </dd>

  <dt><dfn method for="ImageCapture"><code>setOptions()</code></dfn></dt>
  <dd>
  {{setOptions()}} is used to configure a number of settings affecting the image capture and/or the current video feed in {{videoStreamTrack}}. When this method is invoked:
  <ol>
    <li>If the {{readyState}} of a {{videoStreamTrack}} provided in the constructor is not {{live}}, return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{InvalidStateError}}. </li>

    <li>If an invalid {{PhotoSettings}} object is passed as argument, return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{SyntaxError}}</li>

    <li>Otherwise it MUST queue a task, using the DOM manipulation task source, that runs the following steps:
    <ol>
      <li>Configure the underlying image capture device with the {{settings}} parameter.</li>

      <li>If the UA cannot successfully apply the settings, then the UA MUST return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{OperationError}}.</li>

      <li>If the UA can successfully apply the settings, then the UA MUST return a resolved promise.

      <div class="note">
        If the UA can successfully apply the settings, the effect MAY be reflected, if visible at all, in {{videoStreamTrack}}. The result of applying some of the settings MAY force the latter to not satisfy its {{constraints}} (e.g. the frame rate). The result of applying some of this constraints might not be immediate.
      </div></li>
    </ol>
    </li>
  </ol>

  <table class="parameters">
    <tbody>
      <tr>
        <th>Parameter</th>
        <th>Type</th>
        <th>Nullable</th>
        <th>Optional</th>
        <th>Description</th>
      </tr>
      <tr>
        <td class="prmName">settings</td>
        <td class="prmType"><code>PhotoSettings</code></td>
        <td class="prmNullTrue"><span role="img" aria-label=
        "True">&#10004;</span></td>
        <td class="prmOptFalse"><span role="img" aria-label=
        "False">&#10008;</span></td>
        <td class="prmDesc">
          The <code>PhotoSettings</code> dictionary to be applied.
        </td>
      </tr>
    </tbody>
  </table>

  <div class="note">
    Many of the {{PhotoSettings}} represent hardware capabilities that cannot be modified instaneously, e.g. `zoom` or `focus`. {{setOptions()}} will resolve the Promise as soon as possible. The actual status of any field can be monitored using {{getPhotoCapabilities()}}.
  </div>
  </dd>

  <dt><dfn method for="ImageCapture"><code>grabFrame()</code></dfn></dt>
  <dd>{{grabFrame()}} takes a snapshot of the live video being held in {{videoStreamTrack}}, returning an {{ImageBitmap}} if successful. {{grabFrame()}} returns data only once upon being invoked. When this method is invoked:
  <ol>
    <li>If the {{readyState}} of {{videoStreamTrack}} provided in the constructor is not {{live}}, return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{InvalidStateError}}.</li>

    <li>Otherwise it MUST queue a task, using the DOM manipulation task source, that runs the following steps:
    <ol>
      <li>Gather data from {{videoStreamTrack}} into an {{ImageBitmap}} object. The `width` and `height` of the {{ImageBitmap}} object are derived from the constraints of a {{videoStreamTrack}}.
      <div class="note">
        The result of {{grabFrame()}} is affected by any options set by {{setOptions()}} if those are reflected in {{videoStreamTrack}}.
      </div>
      </li>

      <li>Returns a resolved promise with a newly created {{ImageBitmap}} object.</li>

      <li>If the UA is unable to execute the {{grabFrame()}} method for any reason (for example, upon invocation of multiple {{grabFrame()}}/{{takePhoto()}} method calls in rapid succession), then the UA MUST return <a>a promise rejected with</a> a new {{DOMException}} whose name is {{UnknownError}}.</li>
    </ol>
    </li>
  </ol>
  </dd>

</dl>


# PhotoCapabilities

<pre class="idl">
  interface PhotoCapabilities {
    readonly attribute MeteringMode       whiteBalanceMode;
    readonly attribute MediaSettingsRange colorTemperature;
    readonly attribute MeteringMode       exposureMode;
    readonly attribute MediaSettingsRange exposureCompensation;
    readonly attribute MediaSettingsRange iso;
    readonly attribute boolean            redEyeReduction;
    readonly attribute MeteringMode       focusMode;

    readonly attribute MediaSettingsRange brightness;
    readonly attribute MediaSettingsRange contrast;
    readonly attribute MediaSettingsRange saturation;
    readonly attribute MediaSettingsRange sharpness;
    readonly attribute MediaSettingsRange imageHeight;
    readonly attribute MediaSettingsRange imageWidth;
    readonly attribute MediaSettingsRange zoom;
    readonly attribute FillLightMode      fillLightMode;
  };
</pre>

## Attributes

<dl class="domintro">
  <dt><dfn attribute for="PhotoCapabilities"><code>whiteBalanceMode</code></dfn></dt>
  <dd>This reflects the current <a>white balance mode</a> setting. </dd>

  <dt><dfn attribute for="PhotoCapabilities"><code>colorTemperature</code></dfn></dt>
  <dd>This range reflects the current correlated <a>color temperature</a> being used for the scene white balance calculation and its available range.</dd>

  <dt><dfn attribute for="PhotoCapabilities"><code>exposureMode</code></dfn></dt>
  <dd>This reflects the current <a>exposure</a> mode setting.</dd>

  <dt><dfn attribute for="PhotoCapabilities"><code>exposureCompensation</code></dfn></dt>
  <dd>This reflects the current <a>exposure compensation</a> setting and permitted range.  The supported range can be, and usually is, centered around 0 EV.</dd>

  <dt><dfn attribute for="PhotoCapabilities"><code>iso</code></dfn></dt>
  <dd>This reflects the current camera <a>ISO</a> setting and permitted range.  Values are numeric.</dd>

  <dt><dfn attribute for="PhotoCapabilities"><code>redEyeReduction</code></dfn></dt>
  <dd>This reflects whether camera red eye reduction is on or off, and is boolean - on is true</dd>

  <dt><dfn attribute for="PhotoCapabilities"><code>focusMode</code></dfn></dt>
  <dd>This reflects the current focus mode setting.</dd>

  <dt><dfn attribute for="PhotoCapabilities"><code>brightness</code></dfn></dt>
  <dd></dd>
  <dt><dfn attribute for="PhotoCapabilities"><code>contrast</code></dfn></dt>
  <dd></dd>
  <dt><dfn attribute for="PhotoCapabilities"><code>saturation</code></dfn></dt>
  <dd></dd>
  <dt><dfn attribute for="PhotoCapabilities"><code>sharpness</code></dfn></dt>
  <dd></dd>
  <dt><dfn attribute for="PhotoCapabilities"><code>imageHeight</code></dfn></dt>
  <dd></dd>
  <dt><dfn attribute for="PhotoCapabilities"><code>imageWidth</code></dfn></dt>
  <dd></dd>
  <dt><dfn attribute for="PhotoCapabilities"><code>zoom</code></dfn></dt>
  <dd></dd>
  <dt><dfn attribute for="PhotoCapabilities"><code>fillLightMode</code></dfn></dt>
  <dd></dd>
</dl>

## Discussion
<em>This section is non-normative.</em>

  <p>The <code>PhotoCapabilities</code> interface provides the photo-specific settings and their current values.  Many of these fields mirror hardware capabilities that are hard to define since can be implemented in a number of ways.  Moreover, hardware manufacturers tend to publish vague definitions to protect their intellectual property.  The following definitions are assumed for individual settings and are provided for information purposes:</p>
  <ol>
    <li><i><dfn>White balance mode</dfn></i> is a setting that cameras use to adjust for different color temperatures.  <dfn>Color temperature</dfn> is the temperature of background light (usually measured in Kelvin).  This setting can usually be automatically and continuously determined by the implementation, but it's also common to offer a `manual` mode in which the estimated temperature of the scene illumination is hinted to the implementation.  Typical temperature ranges for popular modes are provided below:
        <table class="simple">
        <tr> <th>Mode</th> <th>Kelvin range</th> </tr>
        <tr> <td>incandescent</td> <td>2500-3500</td> </tr>
        <tr> <td>fluorescent</td> <td>4000-5000</td> </tr>
        <tr> <td>warm-fluorescent</td> <td>5000-5500</td> </tr>
        <tr> <td>daylight</td> <td>5500-6500</td> </tr>
        <tr> <td>cloudy-daylight</td> <td>6500-8000</td> </tr>
        <tr> <td>twilight</td> <td>8000-9000</td> </tr>
        <tr> <td>shade</td> <td>9000-10000</td> </tr>
        </table>
        </li>

    <li><i><dfn>Exposure</dfn></i> is the amount of time during which light is allowed to fall on the photosensitive device.  Auto-exposure mode is a camera setting where the exposure levels are automatically adjusted by the implementation based on the subject of the photo.</li>

    <li><i><dfn>Exposure Compensation</dfn></i> is a numeric camera setting that adjusts the exposure level from the current value used by the implementation.  This value can be used to bias the exposure level enabled by auto-exposure, and usually is a symmetric range around 0 EV (the no-compensation value).</li>

    <li>The <i><dfn>ISO</dfn></i> setting of a camera describes the sensitivity of the camera to light. It is a numeric value, where the lower the value the greater the sensitivity.  This value should follow the [[iso12232]] standard.</li>

    <li><i>Red Eye Reduction</i> is a feature in cameras that is designed to limit or prevent the appearance of red pupils ("Red Eye") in photography subjects due prolonged exposure to a camera's flash.</li>

    <li><i>Focus mode</i> describes the focus setting of the capture device (e.g. `auto` or `manual`). </li>

    <li>[[LIGHTING-VOCABULARY]] defines <i><dfn>brightness</dfn></i> as "the attribute of a visual sensation according to which an area appears to emit more or less light" and in the context of the present API, it refers to the numeric camera setting that adjusts the perceived amount of light emitting from the photo object.  A higher brightness setting increases the intensity of darker areas in a scene while compressing the intensity of brighter parts of the scene.  The range and effect of this setting is implementation dependent but in general it translates into a numerical value that is added to each pixel with saturation.</li>

    <li><i><dfn>Contrast</dfn></i> is the numeric camera setting that controls the difference in brightness between light and dark areas in a scene.  A higher contrast setting reflects an expansion in the difference in brightness. The range and effect of this setting is implementation dependent but it can be understood as a transformation of the pixel values so that the luma range in the histogram becomes larger; the transformation is sometimes as simple as a gain factor.</li>

    <li>[[LIGHTING-VOCABULARY]] defines <i><dfn>saturation</dfn></i> as "the colourfulness of an area judged in proportion to its brightness" and in the current context it refers to a numeric camera setting that controls the intensity of color in a scene (i.e. the amount of gray in the scene). Very low saturation levels will result in photos closer to black-and-white. Saturation is similar to <a>contrast</a> but referring to colors, so its implementation, albeit being platform dependent, can be understood as a gain factor applied to the chroma components of a given image.</li>

    <li><i><dfn>Sharpness</dfn></i> is a numeric camera setting that controls the intensity of edges in a scene.  Higher sharpness settings result in higher contrast along the edges, while lower settings result in less contrast and blurrier edges (i.e. soft focus). The implementation is platform dependent, but it can be understood as the linear combination of an edge detection operation applied on the original image and the original image itself; the relative weights being cotrolled by this `sharpness`.

    <div class="note">
      <a>Brightness</a>, <a>contrast</a>, <a>saturation</a> and <a>sharpness</a> are specified in [[UVC]].
    </div></li>

    <li><i>Zoom</i> is a numeric camera setting that controls the focal length of the lens.  The setting usually represents a ratio, e.g. 4 is a zoom ratio of 4:1.  The minimum value is usually 1, to represent a 1:1 ratio (i.e. no zoom).</li>

    <li><i>Fill light mode</i> describes the flash setting of the capture device (e.g. `auto`, `off`, `on`). </li>
  </ol>

# PhotoSettings

<pre class="idl">
  dictionary PhotoSettings {
       MeteringMode whiteBalanceMode;
       double colorTemperature;
       MeteringMode exposureMode;
       double exposureCompensation;
       double iso;
       boolean redEyeReduction;
       MeteringMode focusMode;
       sequence&lt;Point2D> pointsOfInterest;

       double brightness;
       double contrast;
       double saturation;
       double sharpness;
       double zoom;
       double imageHeight;
       double imageWidth;
       FillLightMode fillLightMode;
  };
</pre>

# MediaSettingsRange

<pre class="idl">
  interface MediaSettingsRange {
      readonly attribute double max;
      readonly attribute double min;
      readonly attribute double current;
      readonly attribute double step;
  };
</pre>

# FillLightMode


<pre class="idl">
  enum FillLightMode {
      "unavailable",
      "auto",
      "off",
      "flash",
      "torch"
  };
</pre>

# MeteringMode

<pre class="idl">
  enum MeteringMode {
      "none",
      "manual",
      "single-shot",
      "continuous"
  };
</pre>

# Point2D

<pre class="idl">
  dictionary Point2D {
    double x = 0.0;
    double y = 0.0;
  };
</pre>

# Examples # {#examples}

<div class="note">
  Slightly modified versions of these examples can be found in e.g. <a href="https://codepen.io/collection/nLeobQ/">this codepen collection</a>.
</div>

## Update camera zoom and {{takePhoto()}}

<div class="note">
  An expanded version of this example can be found in e.g. <a href="https://codepen.io/miguelao/pen/BLPzKx/left?editors=1010">this codepen</a>.
</div>

<div class="example" highlight="javascript">
  <pre>
    &lt;html>
    &lt;body>
    &lt;video autoplay>&lt;/video>
    &lt;img>
    &lt;input type="range" hidden>
    &lt;script>
      var imageCapture;

      navigator.mediaDevices.getUserMedia({video: true})
        .then(gotMedia)
        .catch(err => console.error('getUserMedia() failed: ', err));

      function gotMedia(mediastream) {
        const video = document.querySelector('video');
        video.srcObject = mediastream;

        const track = mediastream.getVideoTracks()[0];
        imageCapture = new ImageCapture(track);
        imageCapture.getPhotoCapabilities()
          .then(photoCapabilities => {
            // Check whether zoom is supported or not.
            if (!photoCapabilities.zoom.min && !photoCapabilities.zoom.max) {
              return;
            }

            // Map zoom to a slider element.
            const input = document.querySelector('input[type="range"]');
            input.min = photoCapabilities.zoom.min;
            input.max = photoCapabilities.zoom.max;
            input.step = photoCapabilities.zoom.step;
            input.value = photoCapabilities.zoom.current;
            input.oninput = function(event) {
              imageCapture.setOptions({zoom: event.target.value});
            }
            input.hidden = false;
          })
          .catch(err => console.error('getPhotoCapabilities() failed: ', err));
      }

      function takePhoto() {
        imageCapture.takePhoto()
          .then(blob => {
            console.log('Photo taken: ' + blob.type + ', ' + blob.size + 'B');

            const image = document.querySelector('img');
            image.src = URL.createObjectURL(blob);
          })
          .catch(err => console.error('takePhoto() failed: ', err));
      }
    &lt;/script>
    &lt;/body>
    &lt;/html>
  </pre>
</div>

## Repeated grabbing of a frame
<div class="note">
  The following example can also be found in e.g. <a href="https://codepen.io/miguelao/pen/wzxxwp/left?editors=1010">this codepen</a> with minimal modifications.
</div>

<div class="example" highlight="javascript">
  <pre>
    &lt;html>
    &lt;body>
    &lt;canvas>&lt;/canvas>
    &lt;button onclick="stopGrabFrame()">Stop frame grab&lt;/button>
    &lt;script>
      const canvas = document.querySelector('canvas');

      var interval;
      var track;

      navigator.mediaDevices.getUserMedia({video: true})
        .then(gotMedia)
        .catch(err => console.error('getUserMedia() failed: ', err));

      function gotMedia(mediastream) {
        track = mediastream.getVideoTracks()[0];
        var imageCapture = new ImageCapture(track);
        interval = setInterval(function () {
          imageCapture.grabFrame()
            .then(processFrame)
            .catch(err => console.error('grabFrame() failed: ', err));
        }, 1000);
      }

      function processFrame(imgData) {
        canvas.width = imgData.width;
        canvas.height = imgData.height;
        canvas.getContext('2d').drawImage(imgData, 0, 0);
      }

      function stopGrabFrame(e) {
        clearInterval(interval);
        track.stop();
      }
    &lt;/script>
    &lt;/body>
    &lt;/html>
  </pre>
 </div>

## Grabbing a Frame and Post-Processing
<div class="note">
  The following example can also be found in e.g. <a href="https://codepen.io/miguelao/pen/mAzXpN/left?editors=1010">this codepen</a> with minimal modifications.
</div>

<div class="example" highlight="javascript">
  <pre>
    &lt;html>
    &lt;body>
    &lt;canvas>&lt;/canvas>
    &lt;script>
      const canvas = document.querySelector('canvas');

      var track;

      navigator.mediaDevices.getUserMedia({video: true})
        .then(gotMedia)
        .catch(err => console.error('getUserMedia() failed: ', err));

      function gotMedia(mediastream) {
        track = mediastream.getVideoTracks()[0];
        var imageCapture = new ImageCapture(track);
        imageCapture.grabFrame()
          .then(processFrame)
          .catch(err => console.error('grabFrame() failed: ', err));
      }

      function processFrame(imageBitmap) {
        track.stop();

        // |imageBitmap| pixels are not directly accessible: we need to paint
        // the grabbed frame onto a &lt;canvas>, then getImageData() from it.
        const ctx = canvas.getContext('2d');
        canvas.width = imageBitmap.width;
        canvas.height = imageBitmap.height;
        ctx.drawImage(imageBitmap, 0, 0);

        // Read back the pixels from the &lt;canvas>, and invert the colors.
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

        var data = imageData.data;
        for (var i = 0; i &lt; data.length; i += 4) {
          data[i]     = 255 - data[i];     // red
          data[i + 1] = 255 - data[i + 1]; // green
          data[i + 2] = 255 - data[i + 2]; // blue
        }
        // Finally, draw the inverted image to the &lt;canvas>
        ctx.putImageData(imageData, 0, 0);
      }
    &lt;/script>
    &lt;/body>
    &lt;/html>
  </pre>
</div>







<pre class="anchors">
urlPrefix: https://www.w3.org/TR/mediacapture-streams/#; type: interface; text: MediaStreamTrack; url: mediastreamtrack
</pre>

<pre class="link-defaults">
spec: html
    type: dfn
        text: allowed to show a popup
        text: in parallel
        text: incumbent settings object
</pre>

<pre class="biblio">
{
  "iso12232": {
      "href": "http://www.iso.org/iso/catalogue_detail.htm?csnumber=37777",
      "title": "Photography - Digital still cameras - Determination of exposure index, ISO speed ratings, standard output sensitivity, and recommended exposure index",
      "publisher": "ISO/IEC",
      "date": "15 April 2006"
  },
  "UVC": {
      "href": "http://www.usb.org/developers/docs/devclass_docs/",
      "title": "USB Device Class Definition for Video Devices",
      "publisher": "USB Implementers Forum Inc.",
      "date": "9 August 2012"
  }
}
</pre>
